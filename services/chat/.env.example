# Chat service environment template.
# Used when running chat directly (not required for docker compose, which reads root .env).
# Required by env contract: DATABASE_URL, LLM_PROVIDER, ALLOWED_ORIGINS

# Runtime environment label.
ENVIRONMENT=development

# Allowed CORS origins (comma-separated).
ALLOWED_ORIGINS=http://localhost:3000

# Shared database URL (same Prisma schema as web app).
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/contoso-db

# Provider selection: local or gcp.
LLM_PROVIDER=local

# GCP project id (required when LLM_PROVIDER=gcp).
PROJECT_ID=local

# GCP region used by model/evaluator clients.
REGION=us-central1

# Gemini model id for gcp provider.
GEMINI_MODEL_NAME=gemini-2.5-flash

# Local model id for local provider (Ollama).
LOCAL_MODEL_NAME=gemma3:12b

# Ollama base URL.
OLLAMA_BASE_URL=http://localhost:11434

# Local Chroma persistence directory.
CHROMA_DB_PATH=./data/chroma_db

# Optional Firestore database id for gcp retrieval flows.
FIRESTORE_DATABASE=contoso-db

# Optional Discovery Engine app id.
DISCOVERY_ENGINE_APP_ID=

# Optional Discovery Engine datastore id (required for grounded gcp search path).
DISCOVERY_ENGINE_DATASTORE_ID=
